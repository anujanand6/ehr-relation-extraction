{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS5500_Project_Tokenization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPT7UKf8pnQTvWS2khWDtTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smitkiri/ehr-relation-extraction/blob/master/DS5500_Project_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZoMQhHrcBo"
      },
      "source": [
        "import os\n",
        "import annotations\n",
        "from annotations import Entity, Relation\n",
        "import utils\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import re"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ndC15xb9V4",
        "outputId": "d0e8a7d9-228b-4f4a-992d-1e4e53d24b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bc5cdr_md-0.2.5.tar.gz"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: en-ner-bc5cdr-md\n",
            "Successfully installed en-ner-bc5cdr-md-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeENQKybbwrO"
      },
      "source": [
        "import scispacy\n",
        "import spacy\n",
        "import en_ner_bc5cdr_md\n",
        "\n",
        "nlp = en_ner_bc5cdr_md.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISl63nkOraQm"
      },
      "source": [
        "tags = utils.open_pickle(\"tags.pkl\")\n",
        "\n",
        "# for entity_dict in tags[0:1]:\n",
        "#   for key, value in entity_dict['entities'].items():\n",
        "#       print(value.ranges)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCnjI7-VtlrS"
      },
      "source": [
        "import os\n",
        "directory = '/content/Data/'\n",
        "\n",
        "raw_data = []\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".txt\"):\n",
        "      file_data = open(directory+filename, 'r')\n",
        "      raw_data.append(file_data.read())\n",
        "      file_data.close()\n",
        "      continue\n",
        "    else:\n",
        "      continue"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La8RdZ2e5NIq"
      },
      "source": [
        "print(raw_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo057bKrQX8K"
      },
      "source": [
        "def get_char_to_word_idx(doc_text):\n",
        "        '''\n",
        "        A functions that returns a list which maps each character index to a word index\n",
        "        '''\n",
        "        char_to_word = []\n",
        "        words = re.split(' ', doc_text)\n",
        "\n",
        "        for idx in range(len(words)):\n",
        "            # The space next to a word will be considered as part of that word itself\n",
        "            char_to_word = char_to_word + [idx] * (len(words[idx]) + 1)\n",
        "\n",
        "        # There is no space after last word, so we need to remove the last element\n",
        "        char_to_word = char_to_word[:-1]\n",
        "\n",
        "        # Check for errors\n",
        "        assert len(char_to_word) == len(doc_text)\n",
        "\n",
        "        return char_to_word"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td6M712d5WcB"
      },
      "source": [
        "def tokenizer(doc_text, tokenizer):\n",
        "  token_to_org_map = []\n",
        "  org_to_token_map = []\n",
        "  all_doc_tokens = []\n",
        "  words = re.split(' ', doc_text)\n",
        "\n",
        "  for idx, word in enumerate(words):\n",
        "      org_to_token_map.append(len(all_doc_tokens))\n",
        "      sub_tokens = tokenizer(word)\n",
        "      # See if there are sub-tokens for the space-seperated word\n",
        "      for token in sub_tokens:\n",
        "          token_to_org_map.append(idx)\n",
        "          all_doc_tokens.append(token)\n",
        "  return token_to_org_map, org_to_token_map, all_doc_tokens\n",
        "        "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKz2S5gqQ8pn"
      },
      "source": [
        "char_to_word = get_char_to_word_idx(raw_data[0])\n",
        "char_to_word[:20]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlBgDjK7RAng"
      },
      "source": [
        "token_to_org_map, org_to_token_map, all_doc_tokens = tokenizer(raw_data[0], nlp)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ujmoG_TSuDU",
        "outputId": "3629eb88-a317-447f-ca4f-b9367d1d6627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "all_doc_tokens[50:76]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[MEDICINE, \n",
              " , Allergies, :, , Vicodin, \n",
              " , Attending:[**First, Name3, (, LF, ), 4891, *, *, ], , Chief, Complaint, :, , Post-cardiac, arrest, ,, asthma, exacerbation]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bTOH_xfTVFJ"
      },
      "source": [
        "token_to_org_map[50: 76]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij2URxhrTgP6"
      },
      "source": [
        "org_to_token_map[50: 76]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}